{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Domaakshithareddy/next-word-prediction/blob/main/Next_Word_Prediction_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Required Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Attention\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ],
      "metadata": {
        "id": "PFyJV8lnFY9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzJaYTWuEp-Y",
        "outputId": "4f8fe951-1c3b-43c9-fb70-7d8d382fc0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of preprocessed text: One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.  The bedding was hardly able to cover it and seemed ready to slide off any moment.  His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.  \"What's happened to me?\" he\n",
            "Vocabulary size: 2618\n",
            "Number of sequences: 22044\n",
            "Sample sequence: [ 53 140  56  15]\n"
          ]
        }
      ],
      "source": [
        "# 1. Preprocessing Improvements\n",
        "def preprocess_text(file_path):\n",
        "    # Read the file\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Basic cleaning: remove newlines and special characters, but keep punctuation for context\n",
        "    text = text.replace('\\n', ' ').replace('\\r', '').replace('\\ufeff', '')\n",
        "\n",
        "    # Keep the full text (no deduplication) to preserve context\n",
        "    return text\n",
        "\n",
        "# Load and preprocess the data\n",
        "file_path = \"metamorphosis_clean.txt\"\n",
        "data = preprocess_text(file_path)\n",
        "print(\"Sample of preprocessed text:\", data[:500])\n",
        "\n",
        "# Tokenization with OOV handling\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")  # Add OOV token for unseen words\n",
        "tokenizer.fit_on_texts([data])\n",
        "pickle.dump(tokenizer, open('tokenizer_improved.pkl', 'wb'))  # Save tokenizer\n",
        "\n",
        "# Convert text to sequences\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 for OOV token\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "\n",
        "# Create N-gram sequences (e.g., use 3 words to predict the next one)\n",
        "sequence_length = 3  # Increased from 1 to 3 for more context\n",
        "sequences = []\n",
        "for i in range(sequence_length, len(sequence_data)):\n",
        "    seq = sequence_data[i-sequence_length:i+1]\n",
        "    sequences.append(seq)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "print(\"Number of sequences:\", len(sequences))\n",
        "print(\"Sample sequence:\", sequences[0])\n",
        "\n",
        "# Split into input (X) and output (y)\n",
        "X = sequences[:, :-1]  # All but the last word\n",
        "y = sequences[:, -1]   # The last word\n",
        "y = to_categorical(y, num_classes=vocab_size)  # One-hot encode the output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Model Architecture Enhancements\n",
        "model = Sequential([\n",
        "    # Embedding layer (could be initialized with pre-trained embeddings like GloVe)\n",
        "    Embedding(vocab_size, 50, input_length=sequence_length),  # Increased embedding size from 10 to 50\n",
        "    Bidirectional(LSTM(500, return_sequences=True)),  # Bidirectional LSTM for better context\n",
        "    Bidirectional(LSTM(500)),  # Second Bidirectional LSTM\n",
        "    Dense(500, activation=\"relu\"),  # Reduced from 1000 to 500 for efficiency\n",
        "    Dense(vocab_size, activation=\"softmax\")  # Output layer\n",
        "])\n",
        "\n",
        "# Build and summarize the model\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# 3. Training Optimization\n",
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Train the model with validation split\n",
        "history = model.fit(X, y,\n",
        "                    epochs=150,\n",
        "                    batch_size=128,  # Increased from 64 to 128\n",
        "                    validation_split=0.2,  # 20% validation data\n",
        "                    callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Save the model\n",
        "model.save(\"nextword_improved.keras\")  # Using native Keras format\n",
        "print(\"Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1kVG6pchFV_4",
        "outputId": "bcdb6bba-1b94-4218-aa76-218f6780403d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │         \u001b[38;5;34m130,900\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1000\u001b[0m)             │       \u001b[38;5;34m2,204,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                │       \u001b[38;5;34m6,004,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m500,500\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2618\u001b[0m)                │       \u001b[38;5;34m1,311,618\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">130,900</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,204,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,004,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">500,500</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2618</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,618</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,151,018\u001b[0m (38.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,151,018</span> (38.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,151,018\u001b[0m (38.72 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,151,018</span> (38.72 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 667ms/step - accuracy: 0.0428 - loss: 6.7580 - val_accuracy: 0.0497 - val_loss: 6.2379 - learning_rate: 0.0010\n",
            "Epoch 2/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 644ms/step - accuracy: 0.0555 - loss: 5.8801 - val_accuracy: 0.0535 - val_loss: 6.1409 - learning_rate: 0.0010\n",
            "Epoch 3/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 643ms/step - accuracy: 0.0614 - loss: 5.5987 - val_accuracy: 0.0739 - val_loss: 6.1115 - learning_rate: 0.0010\n",
            "Epoch 4/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 641ms/step - accuracy: 0.0798 - loss: 5.3692 - val_accuracy: 0.0794 - val_loss: 6.1879 - learning_rate: 0.0010\n",
            "Epoch 5/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 601ms/step - accuracy: 0.0967 - loss: 5.1537 - val_accuracy: 0.0832 - val_loss: 6.1621 - learning_rate: 0.0010\n",
            "Epoch 6/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 637ms/step - accuracy: 0.1139 - loss: 4.9264 - val_accuracy: 0.0984 - val_loss: 6.2484 - learning_rate: 0.0010\n",
            "Epoch 7/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 602ms/step - accuracy: 0.1335 - loss: 4.7170 - val_accuracy: 0.0982 - val_loss: 6.3887 - learning_rate: 0.0010\n",
            "Epoch 8/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 643ms/step - accuracy: 0.1425 - loss: 4.5259 - val_accuracy: 0.0996 - val_loss: 6.4815 - learning_rate: 0.0010\n",
            "Epoch 9/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 603ms/step - accuracy: 0.1600 - loss: 4.3367 - val_accuracy: 0.1005 - val_loss: 6.8111 - learning_rate: 0.0010\n",
            "Epoch 10/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 642ms/step - accuracy: 0.1775 - loss: 4.1569 - val_accuracy: 0.1000 - val_loss: 6.9276 - learning_rate: 0.0010\n",
            "Epoch 11/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 600ms/step - accuracy: 0.1905 - loss: 3.9510 - val_accuracy: 0.0980 - val_loss: 7.3124 - learning_rate: 0.0010\n",
            "Epoch 12/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 645ms/step - accuracy: 0.2045 - loss: 3.7550 - val_accuracy: 0.0973 - val_loss: 7.6970 - learning_rate: 0.0010\n",
            "Epoch 13/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 606ms/step - accuracy: 0.2263 - loss: 3.5245 - val_accuracy: 0.0950 - val_loss: 8.1851 - learning_rate: 0.0010\n",
            "Epoch 14/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 613ms/step - accuracy: 0.2556 - loss: 3.2562 - val_accuracy: 0.0905 - val_loss: 8.6689 - learning_rate: 0.0010\n",
            "Epoch 15/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 636ms/step - accuracy: 0.3003 - loss: 2.9647 - val_accuracy: 0.0814 - val_loss: 9.2254 - learning_rate: 0.0010\n",
            "Epoch 16/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 604ms/step - accuracy: 0.3394 - loss: 2.7075 - val_accuracy: 0.0830 - val_loss: 10.0693 - learning_rate: 0.0010\n",
            "Epoch 17/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 638ms/step - accuracy: 0.3976 - loss: 2.4136 - val_accuracy: 0.0742 - val_loss: 10.7508 - learning_rate: 0.0010\n",
            "Epoch 18/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 603ms/step - accuracy: 0.4497 - loss: 2.1345 - val_accuracy: 0.0771 - val_loss: 11.5350 - learning_rate: 0.0010\n",
            "Epoch 19/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 637ms/step - accuracy: 0.5092 - loss: 1.8779 - val_accuracy: 0.0712 - val_loss: 12.4078 - learning_rate: 0.0010\n",
            "Epoch 20/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 628ms/step - accuracy: 0.5631 - loss: 1.6254 - val_accuracy: 0.0717 - val_loss: 13.0163 - learning_rate: 0.0010\n",
            "Epoch 21/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 639ms/step - accuracy: 0.6148 - loss: 1.4189 - val_accuracy: 0.0746 - val_loss: 13.6784 - learning_rate: 0.0010\n",
            "Epoch 22/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 638ms/step - accuracy: 0.6596 - loss: 1.2230 - val_accuracy: 0.0714 - val_loss: 14.5679 - learning_rate: 0.0010\n",
            "Epoch 23/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 640ms/step - accuracy: 0.7202 - loss: 1.0316 - val_accuracy: 0.0739 - val_loss: 15.2232 - learning_rate: 0.0010\n",
            "Epoch 24/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 630ms/step - accuracy: 0.7598 - loss: 0.8809 - val_accuracy: 0.0692 - val_loss: 15.8780 - learning_rate: 0.0010\n",
            "Epoch 25/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 602ms/step - accuracy: 0.7974 - loss: 0.7386 - val_accuracy: 0.0742 - val_loss: 16.6233 - learning_rate: 0.0010\n",
            "Epoch 26/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 607ms/step - accuracy: 0.8288 - loss: 0.6421 - val_accuracy: 0.0739 - val_loss: 17.3313 - learning_rate: 0.0010\n",
            "Epoch 27/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 633ms/step - accuracy: 0.8566 - loss: 0.5416 - val_accuracy: 0.0737 - val_loss: 17.1158 - learning_rate: 0.0010\n",
            "Epoch 28/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 601ms/step - accuracy: 0.8673 - loss: 0.4926 - val_accuracy: 0.0737 - val_loss: 17.5323 - learning_rate: 0.0010\n",
            "Epoch 29/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 611ms/step - accuracy: 0.8855 - loss: 0.4274 - val_accuracy: 0.0687 - val_loss: 17.9284 - learning_rate: 0.0010\n",
            "Epoch 30/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 631ms/step - accuracy: 0.8918 - loss: 0.3898 - val_accuracy: 0.0696 - val_loss: 18.1086 - learning_rate: 0.0010\n",
            "Epoch 31/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 641ms/step - accuracy: 0.8981 - loss: 0.3606 - val_accuracy: 0.0762 - val_loss: 18.4458 - learning_rate: 0.0010\n",
            "Epoch 32/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 600ms/step - accuracy: 0.9014 - loss: 0.3447 - val_accuracy: 0.0753 - val_loss: 18.3768 - learning_rate: 0.0010\n",
            "Epoch 33/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 607ms/step - accuracy: 0.8981 - loss: 0.3411 - val_accuracy: 0.0751 - val_loss: 18.3464 - learning_rate: 0.0010\n",
            "Epoch 34/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 630ms/step - accuracy: 0.9051 - loss: 0.3103 - val_accuracy: 0.0769 - val_loss: 18.5577 - learning_rate: 0.0010\n",
            "Epoch 35/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 602ms/step - accuracy: 0.9039 - loss: 0.3080 - val_accuracy: 0.0712 - val_loss: 18.5760 - learning_rate: 0.0010\n",
            "Epoch 36/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 640ms/step - accuracy: 0.9062 - loss: 0.2919 - val_accuracy: 0.0730 - val_loss: 18.4328 - learning_rate: 0.0010\n",
            "Epoch 37/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 600ms/step - accuracy: 0.9043 - loss: 0.2917 - val_accuracy: 0.0728 - val_loss: 18.6781 - learning_rate: 0.0010\n",
            "Epoch 38/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 601ms/step - accuracy: 0.9040 - loss: 0.2981 - val_accuracy: 0.0735 - val_loss: 18.6142 - learning_rate: 0.0010\n",
            "Epoch 39/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 602ms/step - accuracy: 0.9043 - loss: 0.3001 - val_accuracy: 0.0735 - val_loss: 18.1462 - learning_rate: 0.0010\n",
            "Epoch 40/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 601ms/step - accuracy: 0.8989 - loss: 0.3113 - val_accuracy: 0.0735 - val_loss: 18.4021 - learning_rate: 0.0010\n",
            "Epoch 41/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9009 - loss: 0.3019\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 601ms/step - accuracy: 0.9008 - loss: 0.3021 - val_accuracy: 0.0714 - val_loss: 18.2793 - learning_rate: 0.0010\n",
            "Epoch 42/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 631ms/step - accuracy: 0.9213 - loss: 0.2216 - val_accuracy: 0.0758 - val_loss: 18.8667 - learning_rate: 2.0000e-04\n",
            "Epoch 43/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 641ms/step - accuracy: 0.9210 - loss: 0.1728 - val_accuracy: 0.0769 - val_loss: 19.3223 - learning_rate: 2.0000e-04\n",
            "Epoch 44/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 600ms/step - accuracy: 0.9134 - loss: 0.1725 - val_accuracy: 0.0782 - val_loss: 19.5793 - learning_rate: 2.0000e-04\n",
            "Epoch 45/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 602ms/step - accuracy: 0.9138 - loss: 0.1637 - val_accuracy: 0.0773 - val_loss: 19.7980 - learning_rate: 2.0000e-04\n",
            "Epoch 46/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 602ms/step - accuracy: 0.9134 - loss: 0.1630 - val_accuracy: 0.0776 - val_loss: 19.8478 - learning_rate: 2.0000e-04\n",
            "Epoch 47/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 636ms/step - accuracy: 0.9119 - loss: 0.1688 - val_accuracy: 0.0762 - val_loss: 19.8405 - learning_rate: 2.0000e-04\n",
            "Epoch 48/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 637ms/step - accuracy: 0.9113 - loss: 0.1616 - val_accuracy: 0.0773 - val_loss: 19.9982 - learning_rate: 2.0000e-04\n",
            "Epoch 49/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 637ms/step - accuracy: 0.9185 - loss: 0.1559 - val_accuracy: 0.0785 - val_loss: 20.0879 - learning_rate: 2.0000e-04\n",
            "Epoch 50/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 597ms/step - accuracy: 0.9091 - loss: 0.1665 - val_accuracy: 0.0771 - val_loss: 20.0927 - learning_rate: 2.0000e-04\n",
            "Epoch 51/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 599ms/step - accuracy: 0.9142 - loss: 0.1603 - val_accuracy: 0.0771 - val_loss: 19.9949 - learning_rate: 2.0000e-04\n",
            "Epoch 52/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 634ms/step - accuracy: 0.9144 - loss: 0.1645 - val_accuracy: 0.0792 - val_loss: 20.1536 - learning_rate: 2.0000e-04\n",
            "Epoch 53/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 599ms/step - accuracy: 0.9121 - loss: 0.1655 - val_accuracy: 0.0767 - val_loss: 20.0916 - learning_rate: 2.0000e-04\n",
            "Epoch 54/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559ms/step - accuracy: 0.9117 - loss: 0.1646\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 634ms/step - accuracy: 0.9117 - loss: 0.1647 - val_accuracy: 0.0798 - val_loss: 20.2511 - learning_rate: 2.0000e-04\n",
            "Epoch 55/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 598ms/step - accuracy: 0.9177 - loss: 0.1531 - val_accuracy: 0.0785 - val_loss: 20.4085 - learning_rate: 1.0000e-04\n",
            "Epoch 56/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 638ms/step - accuracy: 0.9167 - loss: 0.1492 - val_accuracy: 0.0798 - val_loss: 20.5694 - learning_rate: 1.0000e-04\n",
            "Epoch 57/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 598ms/step - accuracy: 0.9190 - loss: 0.1435 - val_accuracy: 0.0796 - val_loss: 20.6569 - learning_rate: 1.0000e-04\n",
            "Epoch 58/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 635ms/step - accuracy: 0.9139 - loss: 0.1494 - val_accuracy: 0.0794 - val_loss: 20.7320 - learning_rate: 1.0000e-04\n",
            "Epoch 59/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 629ms/step - accuracy: 0.9144 - loss: 0.1529 - val_accuracy: 0.0794 - val_loss: 20.8037 - learning_rate: 1.0000e-04\n",
            "Epoch 60/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 636ms/step - accuracy: 0.9104 - loss: 0.1547 - val_accuracy: 0.0792 - val_loss: 20.8145 - learning_rate: 1.0000e-04\n",
            "Epoch 61/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 633ms/step - accuracy: 0.9120 - loss: 0.1533 - val_accuracy: 0.0789 - val_loss: 20.7811 - learning_rate: 1.0000e-04\n",
            "Epoch 62/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 600ms/step - accuracy: 0.9129 - loss: 0.1493 - val_accuracy: 0.0807 - val_loss: 20.8408 - learning_rate: 1.0000e-04\n",
            "Epoch 63/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 640ms/step - accuracy: 0.9172 - loss: 0.1483 - val_accuracy: 0.0792 - val_loss: 20.9375 - learning_rate: 1.0000e-04\n",
            "Epoch 64/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 634ms/step - accuracy: 0.9140 - loss: 0.1477 - val_accuracy: 0.0794 - val_loss: 20.8852 - learning_rate: 1.0000e-04\n",
            "Epoch 65/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 601ms/step - accuracy: 0.9125 - loss: 0.1527 - val_accuracy: 0.0778 - val_loss: 20.9539 - learning_rate: 1.0000e-04\n",
            "Epoch 66/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 637ms/step - accuracy: 0.9121 - loss: 0.1543 - val_accuracy: 0.0785 - val_loss: 20.9636 - learning_rate: 1.0000e-04\n",
            "Epoch 67/150\n",
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 601ms/step - accuracy: 0.9173 - loss: 0.1469 - val_accuracy: 0.0798 - val_loss: 20.9579 - learning_rate: 1.0000e-04\n",
            "Epoch 67: early stopping\n",
            "Restoring model weights from the end of the best epoch: 57.\n",
            "Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Improved Prediction Function\n",
        "def predict_next_words(model, tokenizer, text, top_k=3, temperature=1.0, num_words=1):\n",
        "    \"\"\"\n",
        "    Predict the next word(s) with top-K sampling and temperature scaling.\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        tokenizer: Fitted tokenizer\n",
        "        text: Input text (last sequence_length words)\n",
        "        top_k: Number of top predictions to sample from\n",
        "        temperature: Controls randomness (lower = more deterministic)\n",
        "        num_words: Number of words to predict\n",
        "    \"\"\"\n",
        "    for _ in range(num_words):\n",
        "        # Tokenize input text\n",
        "        words = text.split()\n",
        "        if len(words) > sequence_length:\n",
        "            words = words[-sequence_length:]  # Take last sequence_length words\n",
        "\n",
        "        sequence = tokenizer.texts_to_sequences([words])[0]\n",
        "        if len(sequence) < sequence_length:\n",
        "            sequence = [tokenizer.word_index.get(\"<OOV>\", 1)] * (sequence_length - len(sequence)) + sequence  # Pad with OOV\n",
        "\n",
        "        sequence = np.array(sequence).reshape(1, -1)\n",
        "\n",
        "        # Predict probabilities\n",
        "        preds = model.predict(sequence, verbose=0)[0]\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        preds = np.log(preds + 1e-10) / temperature  # Add small constant to avoid log(0)\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # Top-K sampling\n",
        "        top_k_indices = np.argsort(preds)[-top_k:][::-1]\n",
        "        top_k_probs = preds[top_k_indices]\n",
        "        top_k_probs = top_k_probs / np.sum(top_k_probs)  # Normalize probabilities\n",
        "\n",
        "        predicted_index = np.random.choice(top_k_indices, p=top_k_probs)\n",
        "\n",
        "        # Convert index to word\n",
        "        predicted_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                predicted_word = word\n",
        "                break\n",
        "\n",
        "        if predicted_word and predicted_word != \"<OOV>\":\n",
        "            print(f\"Predicted word: {predicted_word}\")\n",
        "            text += \" \" + predicted_word  # Append predicted word for next iteration\n",
        "        else:\n",
        "            print(\"Predicted an unknown word (<OOV>)\")\n",
        "            break"
      ],
      "metadata": {
        "id": "uTKJwFtGFRGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Calculate Perplexity\n",
        "def calculate_perplexity(model, X, y):\n",
        "    loss = model.evaluate(X, y, verbose=0)[0]\n",
        "    perplexity = np.exp(loss)\n",
        "    return perplexity\n",
        "\n",
        "perplexity = calculate_perplexity(model, X, y)\n",
        "print(f\"Model Perplexity: {perplexity:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqQOC9OZFOel",
        "outputId": "221c2761-3d88-45c7-baeb-9347c4e4d165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Perplexity: 69.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Interactive Testing\n",
        "print(\"\\nTesting the model:\")\n",
        "while True:\n",
        "    text = input(\"Enter your line (or 'stop' to exit): \").strip()\n",
        "    if text.lower() == \"stop\":\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        predict_next_words(model, tokenizer, text, top_k=3, temperature=0.8, num_words=1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn0WQnl9FKWz",
        "outputId": "6dafab76-5f3a-4153-e9b2-043dbb4be175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model:\n",
            "Enter your line (or 'stop' to exit): at the dull\n",
            "Predicted word: weather\n",
            "Enter your line (or 'stop' to exit): i am\n",
            "Predicted word: dying\n",
            "Enter your line (or 'stop' to exit): i am cooking\n",
            "Predicted word: enough\n",
            "Enter your line (or 'stop' to exit): what are you\n",
            "Predicted word: shocked\n",
            "Enter your line (or 'stop' to exit): why are we\n",
            "Predicted word: need\n",
            "Enter your line (or 'stop' to exit): the sun\n",
            "Predicted word: across\n",
            "Enter your line (or 'stop' to exit): i love\n",
            "Predicted word: hurriedly\n",
            "Enter your line (or 'stop' to exit): my name is\n",
            "Predicted word: here\n",
            "Enter your line (or 'stop' to exit): what can i \n",
            "Predicted word: bring\n",
            "Enter your line (or 'stop' to exit): good to see\n",
            "Predicted word: it\n",
            "Enter your line (or 'stop' to exit): i am happy for\n",
            "Predicted word: that\n",
            "Enter your line (or 'stop' to exit): how do you \n",
            "Predicted word: travellers\n",
            "Enter your line (or 'stop' to exit): how\n",
            "Predicted word: he\n",
            "Enter your line (or 'stop' to exit): hi \n",
            "Predicted word: the\n",
            "Enter your line (or 'stop' to exit): he is\n",
            "Predicted word: my\n",
            "Enter your line (or 'stop' to exit): he is my\n",
            "Predicted word: unfortunate\n",
            "Enter your line (or 'stop' to exit): he is my unfortunate\n",
            "Predicted word: son\n",
            "Enter your line (or 'stop' to exit): stop\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTesting the model:\")\n",
        "while True:\n",
        "    text = input(\"Enter your line (or 'stop' to exit): \").strip()\n",
        "    if text.lower() == \"stop\":\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        predict_next_words(model, tokenizer, text, top_k=3, temperature=0.8, num_words=3)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ZoIV37m9CF",
        "outputId": "baf5f18b-e2fc-4c1f-cef8-1d797309fa3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model:\n",
            "Enter your line (or 'stop' to exit): at the dull\n",
            "Predicted word: weather\n",
            "Predicted word: drops\n",
            "Predicted word: of\n",
            "Enter your line (or 'stop' to exit): as i \n",
            "Predicted word: did\n",
            "Predicted word: not\n",
            "Predicted word: see\n",
            "Enter your line (or 'stop' to exit): what are we\n",
            "Predicted word: don't\n",
            "Predicted word: know\n",
            "Predicted word: what\n",
            "Enter your line (or 'stop' to exit): i am\n",
            "Predicted word: dying\n",
            "Predicted word: throughout\n",
            "Predicted word: all\n",
            "Enter your line (or 'stop' to exit): how are you\n",
            "Predicted word: need\n",
            "Predicted word: for\n",
            "Predicted word: commerce\n",
            "Enter your line (or 'stop' to exit): can you\n",
            "Predicted word: need\n",
            "Predicted word: teeth\n",
            "Predicted word: in\n",
            "Enter your line (or 'stop' to exit): what can i\n",
            "Predicted word: bring\n",
            "Predicted word: in\n",
            "Predicted word: order\n",
            "Enter your line (or 'stop' to exit): how come\n",
            "Predicted word: in\n",
            "Predicted word: this\n",
            "Predicted word: mood\n",
            "Enter your line (or 'stop' to exit): who are\n",
            "Predicted word: especially\n",
            "Predicted word: looking\n",
            "Predicted word: up\n",
            "Enter your line (or 'stop' to exit): i am in need of\n",
            "Predicted word: the\n",
            "Predicted word: sort\n",
            "Predicted word: that\n",
            "Enter your line (or 'stop' to exit): stop\n",
            "Exiting...\n"
          ]
        }
      ]
    }
  ]
}