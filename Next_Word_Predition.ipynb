{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "\n",
        "# Data cleaning\n",
        "def preprocess_text(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        text = file.read()\n",
        "    return text.replace('\\n', ' ').replace('\\r', '').replace('\\ufeff', '')\n",
        "\n",
        "# Collect data from multiple files\n",
        "file_paths = [\"data1.txt\", \"data2.txt\", \"data3.txt\", \"data4.txt\"]\n",
        "all_data = \"\"\n",
        "\n",
        "for file_path in file_paths:\n",
        "    if os.path.exists(file_path):\n",
        "        data = preprocess_text(file_path)\n",
        "        all_data += data + \" \"\n",
        "        print(f\"Processed {file_path}. Sample: {data[:100]}\")\n",
        "    else:\n",
        "        print(f\"Warning: {file_path} not found. Skipping...\")\n",
        "\n",
        "# Check data size to prevent memory issues\n",
        "print(\"Total preprocessed text length:\", len(all_data))\n",
        "if len(all_data) > 1_000_000_000:\n",
        "    print(\"Warning: Input data is very large. Consider reducing it for stability.\")\n",
        "print(\"Sample of combined preprocessed text:\", all_data[:100])\n",
        "\n",
        "# Markov Chain Algo\n",
        "class EnhancedMarkovChain:\n",
        "    def __init__(self, max_order=3, smoothing_alpha=1.0, beam_width=3):\n",
        "        self.max_order = max_order\n",
        "        self.smoothing_alpha = smoothing_alpha\n",
        "        self.beam_width = beam_width\n",
        "        self.transitions = [defaultdict(Counter) for _ in range(max_order + 1)]\n",
        "        self.vocab = set()\n",
        "        self.probs = [defaultdict(dict) for _ in range(max_order + 1)]\n",
        "\n",
        "    def train(self, text):\n",
        "        try:\n",
        "            words = text.split()\n",
        "            self.vocab.update(words)\n",
        "            vocab_size = len(self.vocab)\n",
        "            print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "            for order in range(self.max_order + 1):\n",
        "                transitions = self.transitions[order]\n",
        "                for i in range(len(words) - order):\n",
        "                    state = tuple(words[i:i + order]) if order > 0 else tuple()\n",
        "                    next_word = words[i + order]\n",
        "                    transitions[state][next_word] += 1\n",
        "\n",
        "            for order in range(self.max_order + 1):\n",
        "                transitions = self.transitions[order]\n",
        "                probs = self.probs[order]\n",
        "                for state in transitions:\n",
        "                    total_count = sum(transitions[state].values())\n",
        "                    for next_word in transitions[state]:\n",
        "                        probs[state][next_word] = ((transitions[state][next_word] + self.smoothing_alpha) /\n",
        "                                                  (total_count + self.smoothing_alpha * vocab_size))\n",
        "                    probs[state]['<UNK>'] = self.smoothing_alpha / (total_count + self.smoothing_alpha * vocab_size)\n",
        "\n",
        "            print(f\"Trained with {len(self.vocab)} unique words and {sum(len(t) for t in self.transitions)} transitions.\")\n",
        "        except MemoryError:\n",
        "            print(\"Error: Out of memory during training. Try reducing max_order or input size.\")\n",
        "            raise\n",
        "\n",
        "    def generate(self, seed_text, num_words=3):\n",
        "        \"\"\"Generate text using beam search with error handling.\"\"\"\n",
        "        try:\n",
        "            words = seed_text.split()\n",
        "            if not words:\n",
        "                words = [random.choice(list(self.vocab))]\n",
        "\n",
        "            beam = [(0.0, words)]\n",
        "\n",
        "            for _ in range(num_words):\n",
        "                new_beam = []\n",
        "                for log_prob, seq in beam:\n",
        "                    state = tuple(seq[-self.max_order:]) if len(seq) >= self.max_order else tuple(seq)\n",
        "                    for order in range(min(self.max_order, len(state)), -1, -1):\n",
        "                        curr_state = state[-order:] if order > 0 else tuple()\n",
        "                        if curr_state in self.transitions[order]:\n",
        "                            probs = self.probs[order][curr_state]\n",
        "                            for next_word, prob in sorted(probs.items(), key=lambda x: -x[1])[:self.beam_width]:\n",
        "                                new_log_prob = log_prob + math.log(prob)\n",
        "                                new_seq = seq + [next_word if next_word != '<UNK>' else random.choice(list(self.vocab))]\n",
        "                                new_beam.append((new_log_prob, new_seq))\n",
        "                            break\n",
        "                    else:\n",
        "                        uniform_prob = 1.0 / len(self.vocab)\n",
        "                        for next_word in random.sample(list(self.vocab), self.beam_width):\n",
        "                            new_log_prob = log_prob + math.log(uniform_prob)\n",
        "                            new_seq = seq + [next_word]\n",
        "                            new_beam.append((new_log_prob, new_seq))\n",
        "\n",
        "                beam = sorted(new_beam, key=lambda x: -x[0])[:self.beam_width]\n",
        "\n",
        "            return \" \".join(beam[0][1][-num_words:])\n",
        "        except Exception as e:\n",
        "            print(f\"Error during generation: {str(e)}\")\n",
        "            return \"Generation failed\"\n",
        "\n",
        "try:\n",
        "    markov = EnhancedMarkovChain(max_order=3, smoothing_alpha=1.0, beam_width=3)\n",
        "    markov.train(all_data)\n",
        "    print(\"Enhanced Markov Chain trained!\")\n",
        "\n",
        "    test_seed = \"The sun\"\n",
        "    print(f\"Seed: {test_seed}\")\n",
        "    print(f\"Prediction: {markov.generate(test_seed, num_words=3)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Session crashed: {str(e)}\")\n",
        "\n",
        "test_sentences = [\n",
        "    \"She walked through the\",     # 1\n",
        "    \"He decided to take\",         # 2\n",
        "    \"He opened the door\",         # 3\n",
        "    \"She smiled at her\",          # 4\n",
        "    \"A strange sound echoed\",     # 5\n",
        "    \"The bell rang at\",           # 6\n",
        "    \"The old house was\",          # 7\n",
        "    \"A loud noise came\",          # 8\n",
        "    \"The teacher explained the\",  # 9\n",
        "    \"The cat jumped onto\",        # 10\n",
        "    \"The dog barked at\",          # 11\n",
        "    \"She painted the walls\",      # 12\n",
        "    \"The car stopped at\",         # 13\n",
        "    \"He shouted across the\",      # 14\n",
        "    \"He drove to the\",            # 15\n",
        "    \"The moon glowed brightly\",   # 16\n",
        "    \"A cold breeze swept\",        # 17\n",
        "    \"He jumped into the\",         # 18\n",
        "    \"He stared at the\",           # 19\n",
        "    \"The fire crackled in\",       # 20\n",
        "    \"I heard a loud\",             # 21\n",
        "    \"The river flowed through\",   # 22\n",
        "    \"He climbed over the\",        # 23\n",
        "    \"A small boat sailed\",        # 24\n",
        "    \"The sun set behind\",         # 25\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    print(f\"Prediction: {markov.generate(sentence, num_words=3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKOQ_M1FxUBx",
        "outputId": "a8ef51f6-c166-4243-bc86-a771b49aa5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data1.txt. Sample: One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed in\n",
            "Processed data2.txt. Sample:  Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle  This eBook is for the\n",
            "Processed data3.txt. Sample: The sun was shining brightly in the clear blue sky, and a gentle breeze rustled the leaves of the ta\n",
            "Processed data4.txt. Sample:     Chapter 1        It is a truth universally acknowledged, that a single man in       possession o\n",
            "Total preprocessed text length: 1797163\n",
            "Sample of combined preprocessed text: One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed in\n",
            "Vocabulary size: 34751\n",
            "Trained with 34751 unique words and 479778 transitions.\n",
            "Enhanced Markov Chain trained!\n",
            "Seed: The sun\n",
            "Prediction: was shining with\n",
            "\n",
            "Input: She walked through the\n",
            "Prediction: dense vegetation, home\n",
            "\n",
            "Input: He decided to take\n",
            "Prediction: a train to\n",
            "\n",
            "Input: He opened the door\n",
            "Prediction: to the living\n",
            "\n",
            "Input: She smiled at her\n",
            "Prediction: with a questioning\n",
            "\n",
            "Input: A strange sound echoed\n",
            "Prediction: in the corridors.\n",
            "\n",
            "Input: The bell rang at\n",
            "Prediction: the time of\n",
            "\n",
            "Input: The old house was\n",
            "Prediction: none other than\n",
            "\n",
            "Input: A loud noise came\n",
            "Prediction: from somewhere downstairs.\n",
            "\n",
            "Input: The teacher explained the\n",
            "Prediction: presence of the\n",
            "\n",
            "Input: The cat jumped onto\n",
            "Prediction: the carpet. His\n",
            "\n",
            "Input: The dog barked at\n",
            "Prediction: the time of\n",
            "\n",
            "Input: She painted the walls\n",
            "Prediction: of the monastery\n",
            "\n",
            "Input: The car stopped at\n",
            "Prediction: the door. He\n",
            "\n",
            "Input: He shouted across the\n",
            "Prediction: room and closed\n",
            "\n",
            "Input: He drove to the\n",
            "Prediction: Hereford Arms where\n",
            "\n",
            "Input: The moon glowed brightly\n",
            "Prediction: in the wintry\n",
            "\n",
            "Input: A cold breeze swept\n",
            "Prediction: out of the\n",
            "\n",
            "Input: He jumped into the\n",
            "Prediction: air like a\n",
            "\n",
            "Input: He stared at the\n",
            "Prediction: door of the\n",
            "\n",
            "Input: The fire crackled in\n",
            "Prediction: the United States\n",
            "\n",
            "Input: I heard a loud\n",
            "Prediction: and authoritative tap.\n",
            "\n",
            "Input: The river flowed through\n",
            "Prediction: the dense vegetation,\n",
            "\n",
            "Input: He climbed over the\n",
            "Prediction: edge of the\n",
            "\n",
            "Input: A small boat sailed\n",
            "Prediction: away from them.\n",
            "\n",
            "Input: The sun set behind\n",
            "Prediction: certain implied warranties\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    while True:\n",
        "        user_input = input(\"\\nEnter a seed sentence (or type 'exit' to quit): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting prediction mode. Goodbye!\")\n",
        "            break\n",
        "        print(f\"Prediction: {markov.generate(user_input, num_words=1)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Interactive session crashed: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i7y7fMNXURd",
        "outputId": "daadc9f9-ecc7-4198-f34d-2dda0c5b4208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter a seed sentence (or type 'exit' to quit): The river flowed through\n",
            "Prediction: the\n",
            "\n",
            "Enter a seed sentence (or type 'exit' to quit): the sun is\n",
            "Prediction: for\n",
            "\n",
            "Enter a seed sentence (or type 'exit' to quit): I am \n",
            "Prediction: not\n",
            "\n",
            "Enter a seed sentence (or type 'exit' to quit): what are you\n",
            "Prediction: doing?\n",
            "\n",
            "Enter a seed sentence (or type 'exit' to quit): what are you\n",
            "Prediction: doing?\n",
            "\n",
            "Enter a seed sentence (or type 'exit' to quit): exit\n",
            "Exiting prediction mode. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}