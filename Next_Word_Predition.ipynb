{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Required Libraries\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "\n",
        "# Preprocessing Improvements\n",
        "def preprocess_text(file_path):\n",
        "    \"\"\"Load and clean text data.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "        text = file.read()\n",
        "    return text.replace('\\n', ' ').replace('\\r', '').replace('\\ufeff', '')\n",
        "\n",
        "# Load and preprocess multiple files\n",
        "file_paths = [\"data1.txt\", \"data2.txt\", \"data3.txt\", \"data4.txt\"]\n",
        "all_data = \"\"\n",
        "\n",
        "for file_path in file_paths:\n",
        "    if os.path.exists(file_path):\n",
        "        data = preprocess_text(file_path)\n",
        "        all_data += data + \" \"\n",
        "        print(f\"Processed {file_path}. Sample: {data[:200]}\")\n",
        "    else:\n",
        "        print(f\"Warning: {file_path} not found. Skipping...\")\n",
        "\n",
        "# Check data size to prevent memory issues\n",
        "print(\"Total preprocessed text length:\", len(all_data))\n",
        "if len(all_data) > 10_000_000:  # Arbitrary threshold (10MB of text)\n",
        "    print(\"Warning: Input data is very large. Consider reducing it for stability.\")\n",
        "print(\"Sample of combined preprocessed text:\", all_data[:500])\n",
        "\n",
        "# Optimized Enhanced Markov Chain\n",
        "class EnhancedMarkovChain:\n",
        "    def __init__(self, max_order=3, smoothing_alpha=1.0, beam_width=3):\n",
        "        self.max_order = max_order\n",
        "        self.smoothing_alpha = smoothing_alpha\n",
        "        self.beam_width = beam_width\n",
        "        self.transitions = [defaultdict(Counter) for _ in range(max_order + 1)]\n",
        "        self.vocab = set()\n",
        "        self.probs = [defaultdict(dict) for _ in range(max_order + 1)]\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"Train the model with multiple orders and optimized probability computation.\"\"\"\n",
        "        try:\n",
        "            words = text.split()\n",
        "            self.vocab.update(words)\n",
        "            vocab_size = len(self.vocab)\n",
        "            print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "            # Train for each order\n",
        "            for order in range(self.max_order + 1):\n",
        "                transitions = self.transitions[order]\n",
        "                for i in range(len(words) - order):\n",
        "                    state = tuple(words[i:i + order]) if order > 0 else tuple()\n",
        "                    next_word = words[i + order]\n",
        "                    transitions[state][next_word] += 1\n",
        "\n",
        "            # Precompute probabilities only for observed transitions\n",
        "            for order in range(self.max_order + 1):\n",
        "                transitions = self.transitions[order]\n",
        "                probs = self.probs[order]\n",
        "                for state in transitions:\n",
        "                    total_count = sum(transitions[state].values())\n",
        "                    for next_word in transitions[state]:  # Only observed next words\n",
        "                        probs[state][next_word] = ((transitions[state][next_word] + self.smoothing_alpha) /\n",
        "                                                  (total_count + self.smoothing_alpha * vocab_size))\n",
        "                    # Add a small probability for unseen words\n",
        "                    probs[state]['<UNK>'] = self.smoothing_alpha / (total_count + self.smoothing_alpha * vocab_size)\n",
        "\n",
        "            print(f\"Trained with {len(self.vocab)} unique words and {sum(len(t) for t in self.transitions)} transitions.\")\n",
        "        except MemoryError:\n",
        "            print(\"Error: Out of memory during training. Try reducing max_order or input size.\")\n",
        "            raise\n",
        "\n",
        "    def generate(self, seed_text, num_words=3):\n",
        "        \"\"\"Generate text using beam search with error handling.\"\"\"\n",
        "        try:\n",
        "            words = seed_text.split()\n",
        "            if not words:\n",
        "                words = [random.choice(list(self.vocab))]\n",
        "\n",
        "            beam = [(0.0, words)]  # (log_prob, sequence)\n",
        "\n",
        "            for _ in range(num_words):\n",
        "                new_beam = []\n",
        "                for log_prob, seq in beam:\n",
        "                    state = tuple(seq[-self.max_order:]) if len(seq) >= self.max_order else tuple(seq)\n",
        "                    for order in range(min(self.max_order, len(state)), -1, -1):\n",
        "                        curr_state = state[-order:] if order > 0 else tuple()\n",
        "                        if curr_state in self.transitions[order]:\n",
        "                            probs = self.probs[order][curr_state]\n",
        "                            # Add top beam_width candidates\n",
        "                            for next_word, prob in sorted(probs.items(), key=lambda x: -x[1])[:self.beam_width]:\n",
        "                                new_log_prob = log_prob + math.log(prob)\n",
        "                                new_seq = seq + [next_word if next_word != '<UNK>' else random.choice(list(self.vocab))]\n",
        "                                new_beam.append((new_log_prob, new_seq))\n",
        "                            break\n",
        "                    else:\n",
        "                        # Fallback to uniform probability over vocab\n",
        "                        uniform_prob = 1.0 / len(self.vocab)\n",
        "                        for next_word in random.sample(list(self.vocab), self.beam_width):\n",
        "                            new_log_prob = log_prob + math.log(uniform_prob)\n",
        "                            new_seq = seq + [next_word]\n",
        "                            new_beam.append((new_log_prob, new_seq))\n",
        "\n",
        "                beam = sorted(new_beam, key=lambda x: -x[0])[:self.beam_width]\n",
        "\n",
        "            return \" \".join(beam[0][1][-num_words:])\n",
        "        except Exception as e:\n",
        "            print(f\"Error during generation: {str(e)}\")\n",
        "            return \"Generation failed\"\n",
        "\n",
        "# Train and test the optimized model\n",
        "try:\n",
        "    markov = EnhancedMarkovChain(max_order=3, smoothing_alpha=1.0, beam_width=3)\n",
        "    markov.train(all_data)\n",
        "    print(\"Enhanced Markov Chain trained!\")\n",
        "\n",
        "    # Test with a sample seed\n",
        "    test_seed = \"The sun\"\n",
        "    print(f\"Seed: {test_seed}\")\n",
        "    print(f\"Prediction: {markov.generate(test_seed, num_words=3)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Session crashed: {str(e)}\")\n",
        "\n",
        "test_sentences = [\n",
        "    \"She walked through the\",     # 2gg\n",
        "    \"He decided to take\",         # 3gg\n",
        "    \"The old house was\",          # 5g\n",
        "    \"A loud noise came\",          # 7gg\n",
        "    \"The teacher explained the\",  # 8gg\n",
        "    \"The cat jumped onto\",        # 10g\n",
        "    \"He opened the door\",         # 12gg\n",
        "    \"She smiled at her\",          # 13gg\n",
        "    \"The dog barked at\",          # 14g\n",
        "    \"She painted the walls\",      # 18g\n",
        "    \"The car stopped at\",         # 24g\n",
        "    \"He shouted across the\",      # 31g\n",
        "    \"A strange sound echoed\",     # 34gg\n",
        "    \"He drove to the\",            # 38g\n",
        "    \"The moon glowed brightly\",   # 41g\n",
        "    \"A cold breeze swept\",        # 43g\n",
        "    \"He jumped into the\",         # 46g\n",
        "    \"The bell rang at\",           # 47gg\n",
        "    \"He stared at the\",           # 52g\n",
        "    \"The fire crackled in\",       # 55g\n",
        "    \"I heard a loud\",             # 59g\n",
        "    \"The river flowed through\",   # 60g\n",
        "    \"He climbed over the\",        # 70g\n",
        "    \"A small boat sailed\",        # 89g\n",
        "    \"The sun set behind\",         # 90g\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    print(f\"\\nInput: {sentence}\")\n",
        "    print(f\"Prediction: {markov.generate(sentence, num_words=3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKOQ_M1FxUBx",
        "outputId": "beace9fd-a6b6-49fa-cd13-f22df5bbc50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data1.txt. Sample: One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could s\n",
            "Processed data2.txt. Sample:  Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle  This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  You may copy it, giv\n",
            "Processed data3.txt. Sample: The sun was shining brightly in the clear blue sky, and a gentle breeze rustled the leaves of the tall trees. People were out enjoying the beautiful weather, some sitting in the park, others taking a \n",
            "Processed data4.txt. Sample:     Chapter 1        It is a truth universally acknowledged, that a single man in       possession of a good fortune, must be in want of a wife.        However little known the feelings or views of su\n",
            "Total preprocessed text length: 1797163\n",
            "Sample of combined preprocessed text: One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.  The bedding was hardly able to cover it and seemed ready to slide off any moment.  His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.  \"What's happened to me?\" he\n",
            "Vocabulary size: 34751\n",
            "Trained with 34751 unique words and 479778 transitions.\n",
            "Enhanced Markov Chain trained!\n",
            "Seed: The sun\n",
            "Prediction: was shining with\n",
            "\n",
            "Input: She walked through the\n",
            "Prediction: dense vegetation, home\n",
            "\n",
            "Input: He decided to take\n",
            "Prediction: a train to\n",
            "\n",
            "Input: The old house was\n",
            "Prediction: none other than\n",
            "\n",
            "Input: A loud noise came\n",
            "Prediction: from somewhere downstairs.\n",
            "\n",
            "Input: The teacher explained the\n",
            "Prediction: presence of the\n",
            "\n",
            "Input: The cat jumped onto\n",
            "Prediction: the carpet. His\n",
            "\n",
            "Input: He opened the door\n",
            "Prediction: to the living\n",
            "\n",
            "Input: She smiled at her\n",
            "Prediction: with a questioning\n",
            "\n",
            "Input: The dog barked at\n",
            "Prediction: the time of\n",
            "\n",
            "Input: She painted the walls\n",
            "Prediction: of the monastery\n",
            "\n",
            "Input: The car stopped at\n",
            "Prediction: the door. He\n",
            "\n",
            "Input: He shouted across the\n",
            "Prediction: room and closed\n",
            "\n",
            "Input: A strange sound echoed\n",
            "Prediction: in the corridors.\n",
            "\n",
            "Input: He drove to the\n",
            "Prediction: \"Defects,\" such as,\n",
            "\n",
            "Input: The moon glowed brightly\n",
            "Prediction: in the wintry\n",
            "\n",
            "Input: A cold breeze swept\n",
            "Prediction: out of the\n",
            "\n",
            "Input: He jumped into the\n",
            "Prediction: air like a\n",
            "\n",
            "Input: The bell rang at\n",
            "Prediction: the time of\n",
            "\n",
            "Input: He stared at the\n",
            "Prediction: door of the\n",
            "\n",
            "Input: The fire crackled in\n",
            "Prediction: the United States\n",
            "\n",
            "Input: I heard a loud\n",
            "Prediction: and authoritative tap.\n",
            "\n",
            "Input: The river flowed through\n",
            "Prediction: the dense vegetation,\n",
            "\n",
            "Input: He climbed over the\n",
            "Prediction: edge of the\n",
            "\n",
            "Input: A small boat sailed\n",
            "Prediction: away from them.\n",
            "\n",
            "Input: The sun set behind\n",
            "Prediction: the Himalayan peaks,\n"
          ]
        }
      ]
    }
  ]
}